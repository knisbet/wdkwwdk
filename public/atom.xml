<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
	<title></title>
	<link href="https://wdkwwdk.com/atom.xml" rel="self" type="application/atom+xml"/>
  <link href="https://wdkwwdk.com"/>
	<generator uri="https://www.getzola.org/">Zola</generator>
	<updated>2022-07-27T00:00:00+00:00</updated>
	<id>https://wdkwwdk.com/atom.xml</id>
	<entry xml:lang="en">
		<title>Taking a look at the Rogers Outage CRTC Letter</title>
		<published>2022-07-27T00:00:00+00:00</published>
		<updated>2022-07-27T00:00:00+00:00</updated>
		<link href="https://wdkwwdk.com/posts/rogers-outage/" type="text/html"/>
		<id>https://wdkwwdk.com/posts/rogers-outage/</id>
		<content type="html">&lt;p&gt;Last week, the CRTC made public a redacted version of the response Rogers filed with answers to the regulators questions. I started my career in wireless telecommunications for a competitor to Rogers here in Canada, and wanted to dig through the outage. I&#x27;ve been out of the industry for a few years now, but my outdated perspective may be of some use here.&lt;&#x2F;p&gt;
&lt;p&gt;Unfortunately, the redacted version removes almost all the useful information for other carriers or other industries to learn from this outage. But I still dug through the report to try and find what useful information I could.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;resources&quot;&gt;Resources&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;regulator-filings&quot;&gt;Regulator Filings&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;CRTC Letter to Rogers: &lt;a href=&quot;https:&#x2F;&#x2F;crtc.gc.ca&#x2F;eng&#x2F;archive&#x2F;2022&#x2F;lt220712.htm&quot;&gt;https:&#x2F;&#x2F;crtc.gc.ca&#x2F;eng&#x2F;archive&#x2F;2022&#x2F;lt220712.htm&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;Rogers response to CRTC (docx): &lt;a href=&quot;https:&#x2F;&#x2F;crtc.gc.ca&#x2F;public&#x2F;otf&#x2F;2022&#x2F;c12_202203868&#x2F;4215445.docx&quot;&gt;https:&#x2F;&#x2F;crtc.gc.ca&#x2F;public&#x2F;otf&#x2F;2022&#x2F;c12_202203868&#x2F;4215445.docx&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;Google docs version of the response: &lt;a href=&quot;https:&#x2F;&#x2F;docs.google.com&#x2F;document&#x2F;d&#x2F;1e8fmZGzy_VaYuLtXgDz62LTh4DfvkPkj&#x2F;edit?usp=sharing&amp;amp;ouid=116779044200847408744&amp;amp;rtpof=true&amp;amp;sd=true&quot;&gt;https:&#x2F;&#x2F;docs.google.com&#x2F;document&#x2F;d&#x2F;1e8fmZGzy_VaYuLtXgDz62LTh4DfvkPkj&#x2F;edit?usp=sharing&amp;amp;ouid=116779044200847408744&amp;amp;rtpof=true&amp;amp;sd=true&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;media-reports&quot;&gt;Media Reports&lt;&#x2F;h2&gt;
&lt;p&gt;If you&#x27;re instead interested in a media level analysis, here are some of the media reports i&#x27;ve found.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.theglobeandmail.com&#x2F;business&#x2F;article-how-a-coding-error-caused-rogers-outage-that-left-millions-without&#x2F;&quot;&gt;How a coding error caused Rogers outage that left millions without service - Globe and Mail&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;nationalpost.com&#x2F;news&#x2F;rogers-shares-explanation-after-unprecedented-outage&#x2F;wcm&#x2F;31db4432-713a-4d70-98ef-56f41957c536&#x2F;amp&#x2F;&quot;&gt;Rogers shares explanation after &#x27;unprecedented&#x27; outage - National Post&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;a href=&quot;https:&#x2F;&#x2F;www.thestar.com&#x2F;business&#x2F;2022&#x2F;07&#x2F;23&#x2F;rogers-unable-to-switch-customers-to-bell-telus-despite-competing-carrier-offers.html&quot;&gt;Rogers unable to switch customers to Bell, Telus, despite competing carrier offers - Toronto Star&lt;&#x2F;a&gt;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h1 id=&quot;crtc-letter&quot;&gt;CRTC Letter&lt;&#x2F;h1&gt;
&lt;p&gt;The letter itself basically outlines that the Canadian Radio-television and Telecommunications Commission (CRTC) wants to inquire into the outage that began on July 8th, 2022. And adds the basis for this outreach, including disruptions to business, emergency services, and more.&lt;&#x2F;p&gt;
&lt;p&gt;You can read the full letter above, but effectively it&#x27;s an outline of questions that Rogers has been asked to respond to. I&#x27;ll go through what I see as the important questions and perspective as we go through the response.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;rogers-response&quot;&gt;Rogers Response&lt;&#x2F;h1&gt;
&lt;p&gt;At a high level, Rogers starts by confirming that they had identified the cause of the outage. &lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;We have identified the cause of the outage to a network system failure following an update in our core IP network during the early morning of Friday July 8th. This caused our IP routing network to malfunction. To mitigate this, we re-established management connectivity with the routing network, disconnected the routers that were the source of the outage, resolved the errors caused by the update and redirected traffic, which allowed our network and services to progressively come back online later that day. While the network issue that caused the full-service outage had largely been resolved by the end of Friday, some minor instability issues persisted over the weekend.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;What I find interesting about this is the reference to minor instability issues that persisted over the weekend. &lt;&#x2F;p&gt;
&lt;p&gt;When I worked on a similar outage, where the underlying core network went down for 20 or 30 minutes, my team spent the next 10 or so hours finding and fixing the glitches in the cellular network. This was mainly in broken states within different equipment. Nothing exposes those bugs as good as taking out the underlying network at all layers at the same time.&lt;&#x2F;p&gt;
&lt;p&gt;For example think of an HTTP proxy. A client comes to the proxy, makes a request, the proxy holds some request state, and sends the request to a server. You probably know exactly what happens and it&#x27;s well tested if the upstream server goes down. Just return an error to the client. If the client loses connection, well understood as well, complete the upstream request, and discard it. But what happens if both the upstream and client networks fail at the same time. You start exercising a code path that combines failures that usually aren&#x27;t as well tested. Combine this with some missing internal state, and you start having failures.&lt;&#x2F;p&gt;
&lt;p&gt;Especially in cellular networks, there are all sorts of state that&#x27;s distributed around the network and needs to be kept in sync for different call procedures. This can result in things like being able to send but not receive an SMS message. &lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;Our engineers and technical experts have been and are continuing to work alongside our global equipment vendors to fully explore the root cause and its effects. 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is another interesting point that might be missed on many that don&#x27;t know the industry. Telecommunication companies primarily operate as integrators of vendors equipment. While this isn&#x27;t always the case, most equipment to build and create the network will be purchased from vendors. So if you want a cellular radio for LTE, you may buy the particular piece of equipment from Nokia, Ericcson, Huawei, or others. &lt;&#x2F;p&gt;
&lt;p&gt;In this model of buying equipment from vendors, it often creates an incentive to blame the vendor for outages. But even harder at times, can be to convince another company to work on a feature or design change to make configuration errors less likely. Or like any complex situation, there is probably plenty of blame to share between both the operator and the vendor.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;Additionally, Rogers will work with governmental agencies and our industry peers to further strengthen the resiliency of our network and improve communication and co-operation during events like this. Most importantly, we will explore additional measures to maintain or transfer to other networks 9-1-1 and other essential services during events like these.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I&#x27;ll dig into this deeper later on. But the failure of 911 services, especially for cell phones seems like an incredibly bad design oversight. Cell phones when not attached to a network, can already do an emergency call on any network the phone can find. So by continuing to advertise the Rogers network throughout the outage, caused phone to stick to the broken network. Or probably caused an unattached phone to scan for an available network, and not find a working 911 network.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;questions-and-answers&quot;&gt;Questions and Answers&lt;&#x2F;h1&gt;
&lt;h2 id=&quot;about-the-outage&quot;&gt;About the outage&lt;&#x2F;h2&gt;
&lt;h3 id=&quot;provide-a-complete-and-detailed-report-on-the-service-outage-that-began-on-8-july-2022&quot;&gt;Provide a complete and detailed report on the service outage that began on 8 July 2022&lt;&#x2F;h3&gt;
&lt;p&gt;Unfortunately it looks like Rogers preferred to keep the full details confidential, and the full timeline was attached as confidential. But included are some high level details.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;The network outage experienced by Rogers on July 8th was the result of a network update that was implemented in the early morning. The business requirements and design for this network change started many months ago. Rogers went through a comprehensive planning process including scoping, budget approval, project approval, kickoff, design document, method of procedure, risk assessment, and testing, finally culminating in the engineering and implementation phases. Updates to Rogers’ core network are made very carefully.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;For those outside of telecom, method of procedure may be unfamiliar. While different companies may operate differently, the method of procedure is basically a document that outlines how a change in the network should be executed. It can be as detailed as every command someone in operations should run to make the change, step by step. It may also contain pre-checks that should be executed.&lt;&#x2F;p&gt;
&lt;p&gt;The philosophy is a sort of separation of inputs, where one engineer will write the procedure for the change to be executed, and then someone tasked with operations will be responsible for execution. I don&#x27;t know if this is how Rogers is using MOPs however.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;Maintenance and update windows always take place in the very early morning hours when network traffic is at its quietest.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I can&#x27;t comment as to Rogers, however I know at other big telecoms in Canada that this isn&#x27;t true for every change. There are plenty of changes that are deemed non-risky, and will be executed when convenient. I&#x27;ve also seen different managers and agenda come into play that try to push against change windows to be more efficient, and often a back and forth on the balance of stability vs getting things done. &lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;The configuration change deleted a routing filter and allowed for all possible routes to the Internet to pass through the routers. As a result, the routers immediately began propagating abnormally high volumes of routes throughout the core network. Certain network routing equipment became flooded, exceeded their capacity levels and were then unable to route traffic, causing the common core network to stop processing traffic. 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This twitter thread likely covers this side of the impact better than I can: https:&#x2F;&#x2F;twitter.com&#x2F;atoonk&#x2F;status&#x2F;1550896347691134977&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;The Rogers outage on July 8, 2022, was unprecedented. As discussed in the previous response, it resulted during a routing configuration change to three Distribution Routers in our common core network. Unfortunately, the configuration change deleted a routing filter and allowed for all possible routes to the Internet to be distributed; the routers then propagated abnormally high volumes of routes throughout the core network. Certain network routing equipment became flooded, exceeded their memory and processing capacity and were then unable to route and process traffic, causing the common core network to shut down. As a result, the Rogers network lost connectivity internally and to the Internet for all incoming and outgoing traffic for both the wireless and wireline networks for our consumer and business customers.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I&#x27;m going to nitpick calling this an unprecedented outage. Based on what I can get out of the report and not being able to see the full internal analysis, this seems fairly predictable. The outage explanation is basically some automation removed a piece of configuration that was essential for the routers to function. Without the configuration, routers within the network went into CPU overload processing routing updates. &lt;&#x2F;p&gt;
&lt;p&gt;Someone knew about this and placed that configuration on the router. &lt;&#x2F;p&gt;
&lt;p&gt;This is a known failure mode for most routing equipment. Most of these big routers seem like big powerful machines, but they tend to be more of a fast path for pushing many millions of packets. And a separate compute for sending and receiving signalling about where those packets should go. The control plane side that does the signalling there are often many ways to overload, which will cause peers to think the router has died. &lt;&#x2F;p&gt;
&lt;h3 id=&quot;how-did-rogers-prioritize-reinstating-services-and-what-repairs-were-required&quot;&gt;How did Rogers prioritize reinstating services and what repairs were required?&lt;&#x2F;h3&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;The prioritization of service restoration was always dependent on which service was most relied upon by Canadians for emergency services. As wireless devices have become the dominant form of communicating for a vast majority of Canadians, the wireless network was the first focus of our recovery efforts. Subsequently, we focused on landline service, which remains another important method to access emergency care. We then the worked to restore data services, particularly for critical care services and infrastructure.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I suspect reality is a bit more nuanced that multiple teams were probably looking at the equipment they were responsible for in parallel. If there was a glitch for some subscribers in the LTE network for example, people who focus on the LTE network were likely addressing that. But from a total outage perspective, I&#x27;m sure teams were focussing more or less in this order.&lt;&#x2F;p&gt;
&lt;p&gt;Having working big outages like this, once the underlying IP network is restored and the upper layer network comes back up, there will be a plethora of impacts, alarms, metrics that need to be sorted through. &lt;&#x2F;p&gt;
&lt;p&gt;When I worked a similar outage for a competitor, the team would find something like call failure rates are 5x normal, but also trending back towards normal. And then it&#x27;s a tough thing to figure out, will it return to normal on its own? Maybe customers are rebooting their phones, so it looks like it&#x27;s returning to normal but only because customers are taking their own actions. What options do we have to clean up the call states that are leading to those failures? Maybe the only tool available doesn&#x27;t know who is and isn&#x27;t working, so the only option is to reset every device. Is resetting every device worth it to move from a 2% failure rate to a normal 0.4% failure rate? &lt;&#x2F;p&gt;
&lt;h3 id=&quot;what-measures-or-steps-were-put-in-place-in-the-aftermath-of-the-earlier-mentioned-april-2021-outage-and-why-they-failed-in-preventing-this-new-outage&quot;&gt;What measures or steps were put in place in the aftermath of the earlier-mentioned April 2021 outage, and why they failed in preventing this new outage?&lt;&#x2F;h3&gt;
&lt;p&gt;Everything substantive in the response to this question was redacted. It&#x27;s unfortunate, because as an industry, including non-telecom like SRE can learn substantially from how Telecoms operate networks as reliable as they are. &lt;&#x2F;p&gt;
&lt;p&gt;Basically Rogers did lots of vague things to prevent similar failures.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;how-did-the-outage-impact-rogers-own-staff-and-their-ability-to-determine-the-cause-of-the-outage-and-restore-services&quot;&gt;How did the outage impact Rogers’ own staff and their ability to determine the cause of the outage and restore services?&lt;&#x2F;h3&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;At the early stage of the outage, many Rogers’ network employees were impacted and could not connect to our IT and network systems.  This impeded initial triage and restoration efforts as teams needed to travel to centralized locations where management network access was established. To complicate matters further, the loss of access to our VPN system to our core network nodes affected our timely ability to begin identifying the trouble and, hence, delayed the restoral efforts.  
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is the inherent difficulty in managing network systems. While in my experience the network architectures tend to be layered, when you&#x27;re also the ISP I can imagine the difficulty in this separation. And problems are rare enough that it gets difficult to predict exactly what outages will knock out employee access.&lt;&#x2F;p&gt;
&lt;p&gt;Alot of the carriers also lease infrastructure from eachother, so one big telco can cause impacts in another.&lt;&#x2F;p&gt;
&lt;p&gt;I almost wonder if there is room for something like Starlink here, as the satellite infrastructure would almost be guaranteed to provide diverse network access to a location, without running additional wires in the ground. &lt;&#x2F;p&gt;
&lt;p&gt;Having experienced a similar failure, when I noticed my home internet and cell phone were all offline, I started driving to the office to get a stable connection to production. That was a long day.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;extent-to-which-rogers-sought-or-received-assistance-from-other-tsps-in-addressing-the-outage-or-situation-arising-from-the-service-interruption&quot;&gt;Extent to which Rogers sought or received assistance from other TSPs in addressing the outage or situation arising from the service interruption?&lt;&#x2F;h3&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;In order to allow our customers to use Bell or TELUS’ networks, we would have needed access to our own Home Location Register (“HLR”), Home Subscriber Server (“HSS”) and Centralized User Database (“CUDB”). This was not possible during the incident. 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Basically what Rogers is describing here are the databases used to track and authenticate mobile devices were also unavailable. In cellular mobility, the network can be thought of as two networks for two different purposes. There is a visited network, more or less the radio towers you connect to. And the home network, which is what actually gives you internet, cellular, SMS, etc services. When you&#x27;re on your own carrier, you&#x27;re using your own carriers visited and home networks. &lt;&#x2F;p&gt;
&lt;p&gt;But when you go somewhere else, say the United States, you change your visited network and keep your home network. What Rogers is basically saying, is there home network was broken, so the other carriers weren&#x27;t able to help, because they wouldn&#x27;t be able to authenticate devices, or connect them back to this home network.&lt;&#x2F;p&gt;
&lt;p&gt;There is some tech that allows for internet connections to only use the visited network, but when I was in the industry this was not commonly deployed.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;Furthermore, given the national nature of this event, no competitor’s network would have been able to handle the extra and sudden volume of wireless customers (over 10.2M) and the related voice&#x2F;data traffic surge. If not done carefully, such an attempt could have impeded the operations of the other carriers’ networks. 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is a key point. I don&#x27;t know that any of the other major carriers would be able to predict how the sudden influx would affect their networks. While telecom is trying to move in a model alot more like SaaS providers that can autoscale equipment, I don&#x27;t know how successful this would be.&lt;&#x2F;p&gt;
&lt;p&gt;Let&#x27;s pick something simple. The number of IP addresses available to be assigned to a phone. The other operators likely only provision enough to cover their own needs. Taking over another carrier in Canada isn&#x27;t an expected failover pattern, so there isn&#x27;t provisioning to handle this need. And IP addresses are likely only 1 of 10,000 different capacity constraints that go into a mobile network.&lt;&#x2F;p&gt;
&lt;p&gt;My 2 cents is the most likely path to even considering allowing something like this would be more akin to multi-sim support. Where you would have credentials on your Sim card for both Rogers and a competitor network and the device could switch, if warranted. And then the possibility of this failover goes into the capacity planning for the networks and is only for customers that need it.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;impact-on-emergency-services&quot;&gt;Impact on Emergency Services&lt;&#x2F;h2&gt;
&lt;p&gt;The impact to emergency services is really why I wanted to dig into this report, and try to understand specifically why Rogers cell phones were unable to make emergency calls. Having done some small work on 911 services for cell phones, normally any device is able to attach to any network, unauthenticated, to make emergency calls. Which means while the Rogers core network was down, something was causing the Rogers radio network to continue to advertise that it was able to take emergency calls. Otherwise the cell phones should have scanned for any available wireless network, and done an emergency attach to get emergency services.&lt;&#x2F;p&gt;
&lt;p&gt;You don&#x27;t need a SIM card in your phone, a valid account, etc to make a 911 call. &lt;&#x2F;p&gt;
&lt;h3 id=&quot;provide-a-complete-and-detailed-report-on-the-impact-on-emergency-services-of-the-outage-that-began-on-8-july-2022-including-but-not-limited-to&quot;&gt;Provide a complete and detailed report on the impact on emergency services of the outage that began on 8 July 2022, including but not limited to:&lt;&#x2F;h3&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;With respect to wireless public alerting service (WPAS”), the Rogers Broadcast Message Center (“BMC”) platform was operable to receive alerts from Pelmorex, the WPAS administrator.  However, broadcast-immediate (“BI”) public alerts could not be delivered to any wireless devices across Rogers’ coverage areas due to the outage. Based on a review of the alerts received into the WPAS BMC platform, the only impact occurred in the Province of Saskatchewan. There were four alerts, and associated updates, received but not delivered to wireless devices in Rogers’ coverage area. There were no other alerts issued, as seen on our WPAS BMC platform.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I interpret this and other areas of the report to basically indicate that the IP core outage caused the cell sites to be unreachable. So to send an alert out to all devices in an area, you need to reach the cell site to send the message to phones.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;With respect to broadcasting (cable TV&#x2F;Radio) alerts, our alert hardware is connected to our IP network. Since we had no connection to the Internet on July 8th, we were unable to send out any alerts on that day in the regions that we were serving.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;And also alerts on services that weren&#x27;t cell sites all use the IP network.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;whether-the-outage-specifically-impacted-the-9-1-1-networks-or-only-the-originating-networks-and-if-the-former-how-was-this-possible-in-light-of-resiliency-and-redundancy-obligations-imposed-by-the-commission&quot;&gt;Whether the outage specifically impacted the 9-1-1 networks or only the originating networks, and if the former, how was this possible in light of resiliency and redundancy obligations imposed by the Commission&lt;&#x2F;h3&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;The outage solely impacted Rogers’ originating network. The 9-1-1 networks that receive calls from originating networks are not operated by Rogers. Rather, they are operated by the three large Canadian Incumbent Local Exchange Carriers (“ILECs”). They were unaffected by the outage.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;This is basically saying that Rogers is not operating the 911 networks themselves, as those are operated by Telus, Bell, and Sasktell across Canada. So the impact was isolated to Rogers network being able to deliver emergency calls to the 911 networks.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;number-of-public-alerts-sent-that-did-not-reach-rogers-customers-broken-down-by-province&quot;&gt;Number of public alerts sent that did not reach Rogers’ customers, broken down by province;&lt;&#x2F;h3&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;Only four (4) alerts were received on Rogers WPAS BMC platform on July 8th. All alerts were in the Province of Saskatchewan. No other alert was issued in Canada on that day:
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;1. WPAS ID 957:  7:40AM CST: Saskatchewan RCMP – Civil Emergency (Dangerous Person)
&lt;&#x2F;span&gt;&lt;span&gt;2. WPAS ID 960:  4:05PM CST: Environment Canada – Tornado (Warning)
&lt;&#x2F;span&gt;&lt;span&gt;3. WPAS ID 964:  4:19PM CST: Environment Canada – Tornado (Warning)
&lt;&#x2F;span&gt;&lt;span&gt;4. WPAS ID 982:  5:31PM CST: Environment Canada – Tornado (Warning)
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I&#x27;m just including this as it adds perspective on the number of alerts Rogers wasn&#x27;t able to deliver across the country that day.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;how-were-9-1-1-calls-processed-during-the-outage-and-whether-they-were-able-to-be-processed-by-other-wireless-networks-within-the-same-coverage-area&quot;&gt;How were 9-1-1 calls processed during the outage and whether they were able to be processed by other wireless networks within the same coverage area&lt;&#x2F;h3&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;As seen in Rogers(CRTC)11July2022-2.i above, Rogers was able to route thousands of 9-1-1 calls on July 8th.  Rogers’ wireless network worked intermittently during that day as we were trying to restore our IP core network, varying region by region.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;...
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;The connection state of the UE to Rogers wireless network, and the stability of our network, determined the ability of Rogers wireless customers to have their 9-1-1 calls processed by other wireless networks within the same coverage area.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;Bell and TELUS confirmed to us that some of our customers were able to connect to their wireless networks in order to place 9-1-1 calls.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;The UE is the User Equipment, basically the cell phone.&lt;&#x2F;p&gt;
&lt;p&gt;I think what Rogers is trying to say, is if the cell phone was in a state where it didn&#x27;t see the Rogers network, like &amp;quot;No Service&amp;quot; on the display, an emergency call would do a network scan and attach to another network with service. &lt;&#x2F;p&gt;
&lt;h3 id=&quot;whether-other-measures-could-have-been-taken-to-re-establish-9-1-1-services-sooner&quot;&gt;Whether other measures could have been taken to re-establish 9-1-1 services sooner&lt;&#x2F;h3&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;No other measures would have helped restore 9-1-1 service on July 8th. One possible option that was explored by Rogers was to shut down our RAN. Normally, if a customer’s device cannot connect to their own carrier’s RAN, they will automatically connect to the strongest signal available, even from another carrier, for the purpose of making a 9-1-1 call. However, since Rogers’ RAN remained in service on July 8th, many Rogers customers phones did not attempt to connect to another network.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If this is the case, what the report doesn&#x27;t talk about at all is that non-Rogers customers could be impacted by this outage as well. If a competitor had very weak coverage, it might scan and find the Rogers network and try to use it for the emergency call, instead of finding a network to use. Or a device that is roaming and in airplane mode and then needs to make an emergency call, will try to attach to the first network it finds.&lt;&#x2F;p&gt;
&lt;p&gt;So if this was the case, the Rogers network behaving like this could have prevented emergency calls from reaching a working network. This certainly would be the minority of devices, but I find this to be infuriating that the network sat there advertising 911 services, for hours, that it could not be delivered.&lt;&#x2F;p&gt;
&lt;h3 id=&quot;what-alternatives-are-available-to-rogers-customers-to-access-9-1-1-services-during-such-outages&quot;&gt;What alternatives are available to Rogers’ customers to access 9-1-1 services during such outages&lt;&#x2F;h3&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;The GSM standard for the routing of 9-1-1 calls implies that a wireless customer always has the option to remove the SIM card from their device and then to place the 9-1-1 call. The handset will register to another wireless network (the one with the strongest signal, even if there are not roaming arrangements).
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;I think the problem is most people wouldn&#x27;t know even what their sim card is, let alone that it can be removed to make a 911 call. But as with above, the problem here appears to be Rogers continued to advertise a 911 network, so the device might still connect.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m also not sure that the strongest signal is correct. With so many frequencies now in use for cellular networks, it can take quite some time to do a full network scan. So I&#x27;m not sure devices in this state will scan all possible networks and then choose the strongest signal. I think but am not sure that the devices would connect to the first network found.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;Further, some newer smart devices have the capability to reconnect automatically to other wireless network for 9-1-1 calls when the home network is down. 
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;If this is the case that&#x27;s great. It would probably be a great idea to put this into the standard.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;&#x2F;h1&gt;
&lt;p&gt;I really wanted to dig into this report, as I&#x27;ve worked these sorts of outages. And they are really difficult, as there are infinite ways to make the problems worse, lots of contradictory information, theories of the root cause, and missing information. It is really difficult to operate these networks.&lt;&#x2F;p&gt;
&lt;p&gt;But what I found most frustrating, was the 911 services. The core network is down, but the radio network is continuing to indicate 911 services. While I only suspect this is the case, there isn&#x27;t a good reason that other networks couldn&#x27;t be used, other than a desire to do so. I really hope this doesn&#x27;t get lost on all the major carriers after this outage.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>ShellGuard: Week 2 - Road to MVP</title>
		<published>2022-07-11T00:00:00+00:00</published>
		<updated>2022-07-11T00:00:00+00:00</updated>
		<link href="https://wdkwwdk.com/posts/shellguard-week-002/" type="text/html"/>
		<id>https://wdkwwdk.com/posts/shellguard-week-002/</id>
		<content type="html">&lt;p&gt;There isn&#x27;t a huge deal of progress to talk about this week. Most of the progress has been in intangible areas. The product demo I&#x27;ve been working on is making steady progress, but it offers no security benefits. So it&#x27;s more of a UX demo, and will need to be rebuilt to offer an actual MVP. &lt;&#x2F;p&gt;
&lt;p&gt;So now that I&#x27;m able to demonstrate most UX patterns I&#x27;m thinking of for ShellGuard, I&#x27;m starting to consider when to pivot into an MVP. The smallest product that provides real security benefits, so that I can start getting users. I think I&#x27;ve figured out enough for an MVP, so it&#x27;s time to consider how much further I want to take the demo.&lt;&#x2F;p&gt;
&lt;p&gt;On the non-tangible side, I&#x27;ve binge read &lt;a href=&quot;http:&#x2F;&#x2F;momtestbook.com&#x2F;&quot;&gt;The Mom Test&lt;&#x2F;a&gt; to better ask the right product questions, and been doing some research into other approaches. Basically, I want to figure out if there is a market here or not. If shell and user security is an area companies will care about enough to invest into solutions, if new solutions are presented.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;ve also started thinking about how to design the best UX patterns. This is harder than it might seem, as even in the prototype there is already conflicting language that would be confusing for users. &lt;&#x2F;p&gt;
&lt;p&gt;Anyways, not a huge amount to report, but making some steady progress.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>ShellGuard: Week 1</title>
		<published>2022-07-02T00:00:00+00:00</published>
		<updated>2022-07-02T00:00:00+00:00</updated>
		<link href="https://wdkwwdk.com/posts/shellguard-week-001/" type="text/html"/>
		<id>https://wdkwwdk.com/posts/shellguard-week-001/</id>
		<content type="html">&lt;p&gt;This week, I decided to start a new project called ShellGuard. For the last year or so, I&#x27;ve had an itch. It all started with a customer at &lt;a href=&quot;https:&#x2F;&#x2F;goteleport.com&#x2F;&quot;&gt;Teleport&lt;&#x2F;a&gt; who had concerns about system administrators ability to access customer data on the systems they administer.&lt;&#x2F;p&gt;
&lt;p&gt;My knee-jerk thought is this is an impossible problem. The security controls don&#x27;t create a clear way to allow a user to change the system, but not touch data. Even if you can write some clever selinux policy or BPF rules, it&#x27;s generally trivial to bypass that protection.&lt;&#x2F;p&gt;
&lt;p&gt;Even if we narrow our view to just audit, common syscall &#x2F; BPF audit mechanisms are easy to bypass. They&#x27;re more for theatre than actually catching a sophisticated breach of security.&lt;&#x2F;p&gt;
&lt;p&gt;But it bugged me... badly... that we can&#x27;t restrict access. &lt;&#x2F;p&gt;
&lt;p&gt;And that&#x27;s where the idea of ShellGuard came in. We already have technologies for running untrusted workloads on a Linux host. Things like (gVisor)[https:&#x2F;&#x2F;gvisor.dev&#x2F;] and (Firecracker)[https:&#x2F;&#x2F;firecracker-microvm.github.io&#x2F;] provide lightweight ways to virtualize or isolate workloads. What strikes me about a solution like gVisor, is basically the ability to redirect syscall handling to another application. Why can&#x27;t we do the same thing with a shell session. If we wrap the user session within an application Kernel like gvisor, and insert ourselves between the user and kernel, we can implement a new policy engine.&lt;&#x2F;p&gt;
&lt;p&gt;This idea fascinated me for a few reasons. &lt;&#x2F;p&gt;
&lt;p&gt;A user can really be setup with a read only view of the host. Policy could be designed in a way where a user really has multiple use cases. I need internet access to GitHub and database access. A user running untrusted software could be exploited to upload the database to GitHub. But what if you could write a policy that says, you can get internet access and database access, but not at the same time. There isn&#x27;t a path left open customer data to reach the internet, even if the user needs both as part of their job.&lt;&#x2F;p&gt;
&lt;p&gt;So week 1 has mostly been about getting started. I&#x27;ve started to put together a tech demo, so that I can begin to show the concept and how it would work. I really thought isolating user access impossible... but the more I think about it, the more I believe in a world where sensitive access can be segmented away. &lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Outage Stories: When DNS takes out cell phone roaming</title>
		<published>2022-05-29T00:00:00+00:00</published>
		<updated>2022-05-29T00:00:00+00:00</updated>
		<link href="https://wdkwwdk.com/posts/outage-stories-dns/" type="text/html"/>
		<id>https://wdkwwdk.com/posts/outage-stories-dns/</id>
		<content type="html">&lt;p&gt;When I used to work in Telecom networks, on technologies like LTE or UMTS, I was often tasked with investigating and resolving hard problems. A number of these outages were caused by the way Telecom networks use and deploy a DNS architecture separated from the internet. It&#x27;s the same protocol, but runs on it&#x27;s own networks with separate root servers and a few oddities you wouldn&#x27;t expect on the internet.&lt;&#x2F;p&gt;
&lt;p&gt;In this post I&#x27;ll talk about one of the outages I investigated, where planned maintenance, an unplanned outage, and a miss-configuration led to a triple redundant architecture going down and breaking users roaming into Canada from getting an internet connection.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;ve been out of the industry for a number of years now and I&#x27;m putting this back together from memory, so there may be some inaccuracy. &lt;&#x2F;p&gt;
&lt;h2 id=&quot;background&quot;&gt;Background&lt;&#x2F;h2&gt;
&lt;p&gt;At the time, network operators such as the one I worked for generally operated as integrators of proprietary solutions. Think of a company like Cisco, that makes large scale routers for carrier grade networks, the same applies to Wireless. This generally creates a few challenges, troubleshooting requires builtin tools, logs, metrics or to look at the equipment externally, such as by taking traffic captures. We rarely had the source code or internal knowledge of the products.&lt;&#x2F;p&gt;
&lt;p&gt;When our company originally deployed its 3G wireless network, someone just built a half dozen linux servers and installed ISC BIND to act as DNS servers. These DNS servers were effectively used for service discovery within the network, and to facilitate roaming between networks from different carriers. Because these servers were just thrown in as a network build out in a company culture at the time that doesn&#x27;t really manage servers, they immediately went unmaintained. &lt;&#x2F;p&gt;
&lt;p&gt;These unmaintained DNS servers were eventually replaced with a new set of DNS servers that were provided by a vendor as an appliance and had a team assigned to maintain the new system with proper vendor support for hardware and software. &lt;&#x2F;p&gt;
&lt;p&gt;Even though all of this service discovery was built on the DNS protocol, LTE and UMTS used an architecture completely isolated from the internet, with its own set of root servers and a nice set of standards violations which caused a nice set of problems. In our case, the root servers were provided by a roaming exchange, which can be thought of as a company that exists to connect wireless carriers and facilitate how your cell phone can move from one carrier to another.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-outage&quot;&gt;The Outage&lt;&#x2F;h2&gt;
&lt;p&gt;The roaming exchange we were partnered with normally had 3 DNS servers in operation. These servers are sort of a combination of DNS roots and Zone servers in one. In internet terms, it’s as if the root and .com servers were running on the same machines. But these are not the internet root servers, they&#x27;re something custom just for the wireless telecoms. &lt;&#x2F;p&gt;
&lt;p&gt;The roaming exchange had taken one of their servers down for extended maintenance and then experienced an outage on a second server. And our connectivity to international networks went down, even though there should have been one working server. From our perspective, it was as if the internet root servers all disappeared. Our internal network was fine, just the rest of the world blinked out of existence. &lt;&#x2F;p&gt;
&lt;p&gt;The outage was eventually recovered by the roaming exchange fixing one of the down DNS servers.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-investigation&quot;&gt;The Investigation&lt;&#x2F;h2&gt;
&lt;p&gt;For 2 of 3 root servers, the root cause was pretty straightforward and was up to the partner to solve. The problem I was brought in to investigate, is why we weren’t working with the third server which according to the partner was online and working throughout the outage. No other complaints according to them.&lt;&#x2F;p&gt;
&lt;p&gt;The summary of the initial findings was something along the lines of:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;There was no network cause for the failure. We could reach the server. &lt;&#x2F;li&gt;
&lt;li&gt;Testing and packet captures showed bi-directional communications:
&lt;ul&gt;
&lt;li&gt;Normal communications for several seconds after DNS service was restarted on our new DNS resolvers.&lt;&#x2F;li&gt;
&lt;li&gt;Manual queries from the host were working, despite the server itself not trying to communicate with the particular root.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;Our old DNS servers were still running and did not experience an outage to the working server.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Note: The new and old servers were both based on ISC Bind, but different versions.&lt;&#x2F;p&gt;
&lt;p&gt;Inspecting the DNS caches on the new servers, showed records related to the working root server were missing, while records towards other roots were present.&lt;&#x2F;p&gt;
&lt;p&gt;At the time I likely had an average understanding of the DNS protocols and services, similar to anyone who has had to configure records to set up a website. We engaged our vendor support and began working with someone whose expertise was specifically in the DNS protocol and specifications, and even escalated to basically the guy who wrote the book on DNS. The outcome of that discussion was that the vendor would write us a custom patch, just for us, the exact details of which I don’t remember.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;the-sniff-test&quot;&gt;The Sniff Test&lt;&#x2F;h2&gt;
&lt;p&gt;The difficulty was that this solution didn’t seem to pass the sniff test. There were too many unexplained components to the problem, that writing a patch may or may not resolve. But if nothing else, it was clear that we hadn’t established at this point what the problem was, and suggesting patches or features was premature.&lt;&#x2F;p&gt;
&lt;p&gt;So I set up several VMs that I could use to simulate every host in the production network. I queried the real servers, and then configured my simulation with matching records. I had effectively recreated the production DNS servers of our company, the roaming exchange, and a roaming partner. I was able to reproduce the problem and began experimenting.&lt;&#x2F;p&gt;
&lt;p&gt;I built 10-20 releases of Bind, covering the versions between our old and new servers until I had isolated a series of patches where the problem began. I went through the release notes and nothing stood out but found that the patch that broke our DNS was more than a year old. It seemed unlikely that we were the only ones to have this problem across a year+ of patches. I ended up setting aside this line of investigation before investigating the source code for each patch.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;clues&quot;&gt;Clues&lt;&#x2F;h2&gt;
&lt;p&gt;Using the simulation I eventually narrowed in on a set of clues:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;In the vendor UI, the root servers were simply called something like root server configuration. However, in Bind we configure a “Root Hints”, an initial set of records to locate other DNS servers. &lt;&#x2F;li&gt;
&lt;li&gt;When starting Bind and inspecting the caches, records within the root hints would be present.&lt;&#x2F;li&gt;
&lt;li&gt;Going packet by packet through the startup sequence, there was a discrepancy in the responses to AAAA queries to the root servers for the names of the root servers. The working servers would return a no data result. The non-working root would return a name error response to the AAAA query.
&lt;ul&gt;
&lt;li&gt;Note: This was an IPv4 only network, so it didn’t seem like focussing on AAAA (IPv6 records) was an important detail at the time. Turns out it was quite important.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;&#x2F;li&gt;
&lt;li&gt;After the startup queries were returned, the records for the root server were missing from the cache.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;I reread the DNS standards a couple of times, top to bottom until the following section of &lt;a href=&quot;https:&#x2F;&#x2F;datatracker.ietf.org&#x2F;doc&#x2F;html&#x2F;rfc1034&quot;&gt;RFC 1034&lt;&#x2F;a&gt; stood out.&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;When the resolver performs the indicated function, it usually has one of
&lt;&#x2F;span&gt;&lt;span&gt;the following results to pass back to the client:
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;   - One or more RRs giving the requested data.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;     In this case the resolver returns the answer in the
&lt;&#x2F;span&gt;&lt;span&gt;     appropriate format.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;   - A name error (NE).
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;     This happens when the referenced name does not exist.  For
&lt;&#x2F;span&gt;&lt;span&gt;     example, a user may have mistyped a host name.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;   - A data not found error.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;     This happens when the referenced name exists, but data of the
&lt;&#x2F;span&gt;&lt;span&gt;     appropriate type does not.  For example, a host address
&lt;&#x2F;span&gt;&lt;span&gt;     function applied to a mailbox name would return this error
&lt;&#x2F;span&gt;&lt;span&gt;     since the name exists, but no address RR is present.
&lt;&#x2F;span&gt;&lt;span&gt;
&lt;&#x2F;span&gt;&lt;span&gt;It is important to note that the functions for translating between host
&lt;&#x2F;span&gt;&lt;span&gt;names and addresses may combine the &amp;quot;name error&amp;quot; and &amp;quot;data not found&amp;quot;
&lt;&#x2F;span&gt;&lt;span&gt;error conditions into a single type of error return, but the general
&lt;&#x2F;span&gt;&lt;span&gt;function should not.  One reason for this is that applications may ask
&lt;&#x2F;span&gt;&lt;span&gt;first for one type of information about a name followed by a second
&lt;&#x2F;span&gt;&lt;span&gt;request to the same name for some other type of information; if the two
&lt;&#x2F;span&gt;&lt;span&gt;errors are combined, then useless queries may slow the application.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;It’s subtle...&lt;&#x2F;p&gt;
&lt;p&gt;Analyzing DNS as a protocol, it’s easy to think of a request and response for a particular record type as an independent operation. From the way we interact with and configure DNS servers, we create records independent of each other. But this particular portion of the standard allows a caching resolver to draw a relationship between different record types based on the error result, specifically whether the name exists for other record types.&lt;&#x2F;p&gt;
&lt;p&gt;So BIND was drawing the inference it was supposed to, the particular name received a name error (NXDomain) response, which meant the name doesn’t exist for any record type. So when performing an IPv6 system query, it should delete all records from its cache that contain the name that doesn’t exist, even those entries that we statically configured in our hints file for the IPv4 address of our root server.&lt;&#x2F;p&gt;
&lt;p&gt;So our IPv4 records for who is root, were getting deleted by system queries that were checking to see if any IPv6 addresses were available for those root servers. &lt;&#x2F;p&gt;
&lt;h2 id=&quot;root-cause&quot;&gt;Root Cause&lt;&#x2F;h2&gt;
&lt;p&gt;With this breakthrough, I was able to document what was happening:&lt;&#x2F;p&gt;
&lt;ol&gt;
&lt;li&gt;During startup&#x2F;reset, the DNS server would load the root hints and prepopulate the cache to use those roots.&lt;&#x2F;li&gt;
&lt;li&gt;During startup, it would also see it only has a bunch of IPv4 roots, so would start querying the roots for the equivalent IPv6 records.&lt;&#x2F;li&gt;
&lt;li&gt;For one of the upstream servers, the response for IPv6 records would return NXDomain, which we now know that name doesn’t exist anywhere and would clear the matching IPv4 records from the cache. The missing records from the cache wouldn’t allow the particular server to be used as a root.&lt;&#x2F;li&gt;
&lt;li&gt;There is one detail I’m not sure I remember accurately, which is how the servers were responding to the root system query and the interaction with these statically configured records. &lt;&#x2F;li&gt;
&lt;li&gt;Our new servers had never worked with this one root server, it was missed during commissioning that the root server was not being used and had never worked since the new servers were added.&lt;&#x2F;li&gt;
&lt;li&gt;The underlying BIND implementation didn’t always implement this behaviour, buried in a patch somewhere is an update to follow the standard more closely, as in it’s plausible a bug was just noticed and fixed.&lt;&#x2F;li&gt;
&lt;li&gt;We had the wrong server name on both the old and new servers, only the new servers had the relevant patches. If we had kept the old servers routinely patched, they would have had the same problem.&lt;&#x2F;li&gt;
&lt;li&gt;One of the server names we had for the roots was wrong, this is why we were getting an NXDomain response on the AAAA query instead of a no records response.&lt;&#x2F;li&gt;
&lt;&#x2F;ol&gt;
&lt;p&gt;If the 3 roaming exchange servers were called:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;dns1.grx.gsma.
&lt;&#x2F;span&gt;&lt;span&gt;dns2.grx-partner.gsma.
&lt;&#x2F;span&gt;&lt;span&gt;dns3.grx-partner.gsma.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;Our configuration was:&lt;&#x2F;p&gt;
&lt;pre data-lang=&quot;txt&quot; style=&quot;background-color:#31333d;color:#ffffffc4;&quot; class=&quot;language-txt &quot;&gt;&lt;code class=&quot;language-txt&quot; data-lang=&quot;txt&quot;&gt;&lt;span&gt;dns1.grx.gsma.
&lt;&#x2F;span&gt;&lt;span&gt;dns2.grx.gsma.
&lt;&#x2F;span&gt;&lt;span&gt;dns3.grx-partner.gsma.
&lt;&#x2F;span&gt;&lt;&#x2F;code&gt;&lt;&#x2F;pre&gt;
&lt;p&gt;As I recall, the way this problem happened was that the roaming partner was rebuilding their DNS servers one by one. And the rebuilt servers were using a new naming scheme, but they had gotten ahead of themselves and the datasheet used to exchange information between companies was out of date or miss-matched, so we still had an old name for a new server with the same IP address. &lt;&#x2F;p&gt;
&lt;p&gt;This allowed us to draw one more conclusion, we were the only carrier partnered with this roaming exchange using BIND that had updated our installation in the previous year, because we were the only ones who reported going down when the other two root servers were down. &lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Bitcoin isn&#x27;t for everyone</title>
		<published>2022-05-14T00:00:00+00:00</published>
		<updated>2022-05-14T00:00:00+00:00</updated>
		<link href="https://wdkwwdk.com/posts/bitcoin/" type="text/html"/>
		<id>https://wdkwwdk.com/posts/bitcoin/</id>
		<content type="html">&lt;p&gt;Bitcoin can be a polarizing topic. There are certainly a strong following of bitcoin and derivatives, but many of the engineers I know are opposed to the technology. &lt;&#x2F;p&gt;
&lt;p&gt;What motivated me to finally get this post out however, is the other week I encountered a non-engineer, non-technical advocate for Bitcoin. They were a restaurant worker, and explained they have a side gig of helping others gt into bitcoin. And we had a bit of a discussion on why I don&#x27;t believe in Bitcoin, or derivatives, as a form of asset, payment, etc.&lt;&#x2F;p&gt;
&lt;p&gt;And it comes down to, sitting at a restaurant, look around the room, who in that room can effectively and safely use Bitcoin. &lt;&#x2F;p&gt;
&lt;h1 id=&quot;who-can-safely-use-bitcoin&quot;&gt;Who can safely use Bitcoin?&lt;&#x2F;h1&gt;
&lt;p&gt;Almost no one.&lt;&#x2F;p&gt;
&lt;p&gt;In the tech industry, working with very technical folks, it&#x27;s easy to forget most people are not tech workers. Computers are a tool too many, but they don&#x27;t understand how they work. &lt;&#x2F;p&gt;
&lt;p&gt;I had a conversation with my Sister once, where I tried to explain just what a block chain is. And she didn&#x27;t get it. Not that knowing how it works is necessary. The problem with bitcoin is, someone needs to handle some secrets pretty securely to not lose all of their money. Look around the room, and identify who can really employ the personal security required to effectively use cold wallets, verify destination addresses, not to store their secret incorrectly, backup the secrets incase of a hard drive failure, etc. All techniques required to ensure their money doesn&#x27;t disappear.&lt;&#x2F;p&gt;
&lt;p&gt;So I think Bitcoin has a unstated premise, that users need a high degree of expertise in best practices to even use the technology.&lt;&#x2F;p&gt;
&lt;p&gt;Most people don&#x27;t have the time for this, or the technical basis to even learn it.&lt;&#x2F;p&gt;
&lt;h1 id=&quot;what-bitcoin-doesn-t-do&quot;&gt;What bitcoin doesn&#x27;t do?&lt;&#x2F;h1&gt;
&lt;p&gt;Living in a stable western democracy, I think there is a bit of a flaw in the concept of Bitcoin. In our techno sphere where we&#x27;re used to controlling computers through our code, we forget that our current money system has lots of checks and balances in place, and banking over decades has built many rules to accommodate exceptions, many of which we as individuals have never had to deal with in our lives.&lt;&#x2F;p&gt;
&lt;p&gt;So I like to think of problems in the sense of properties:&lt;&#x2F;p&gt;
&lt;h2 id=&quot;mistakes&quot;&gt;Mistakes&lt;&#x2F;h2&gt;
&lt;p&gt;Mistakes will happen. Many by user input failures, ignoring checks and balances, software bugs, rushing, or even hardware failures that corrupt memory. The current banking system doesn&#x27;t always get this right, and it may not be instant, but in many cases banking failures can be corrected. &lt;&#x2F;p&gt;
&lt;p&gt;Bitcoin, as a cryptographic ledger, immortalizing all mistakes. The only reversible change in the theory of blockchains, is to have the destination run a second transaction to return an amount. Sure, developers have gotten together to tamper with some of the chains to reverse problems before, but no one is fixing the $1000 sent to an address that doesn&#x27;t exist.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;power-of-attorney-estate&quot;&gt;Power of attorney &#x2F; Estate&lt;&#x2F;h2&gt;
&lt;p&gt;It&#x27;s easy to forget, that in some circumstances at some point in our lives our assets may need to be turned over to others. Whether it&#x27;s a death, and turning over the estate, or some other condition that leads to or requires power of attorney. &lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m sure the Bitcoin advocates can point to failures of this system, or unjust conservatorship that&#x27;s been applied. But on average, this is a system that applies to millions of people, that doesn&#x27;t really have a Bitcoin equivalent. Recovery from sudden death, means a pre-planned method of preserving and turning over secrets, that not many will do. And then the additional operational security of only having the secrets turned over when required, and that the storage of those secrets doesn&#x27;t become the weak link to steal all of someones &amp;quot;money&amp;quot;.&lt;&#x2F;p&gt;
&lt;p&gt;And something as simple as rotating your secrets, now requires many additional steps.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;court-orders&quot;&gt;Court orders&lt;&#x2F;h2&gt;
&lt;p&gt;So you went to court, got a judgement. Maybe it&#x27;s big, maybe it&#x27;s small. And the opponent doesn&#x27;t pay what is ordered by the court. Bitcoin removes an option here for enforcement, if the money is sitting in a bank. If the judgement is large and the party simply decides not to pay, are you going to garnish wages for the next 20 years? When the money you&#x27;re owed is just sitting their.&lt;&#x2F;p&gt;
&lt;p&gt;Hell, in these types of conflicts someone could in a fit of deviancy decide to just destroy the amount by transferring to nowhere instead of complying with the judgement, and then good luck.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m just waiting for the first court cases to explore Blockchains, and orders for transfers. &lt;&#x2F;p&gt;
&lt;h2 id=&quot;legal-enforcement&quot;&gt;Legal Enforcement&lt;&#x2F;h2&gt;
&lt;p&gt;I realize for many this might be a feature, but I think of it as a bug. For the most part I agree with law enforcement holds, as long as their is a strong judiciary process, and government sanctions. Can someone find a sanction I disagree with, of course. But I also live in a represented society where I&#x27;m not going to agree with every law enforcement or government decision, and that&#x27;s fine.&lt;&#x2F;p&gt;
&lt;p&gt;And there are real problems with some of these systems, asset forfeiture is rampant, but do I really believe that using a digital wallet is going to stop a government from stealing my stuff. We need to demand better of our institutions where they fail, not work around them and opening the flood gates for criminal behaviour. &lt;&#x2F;p&gt;
&lt;h1 id=&quot;for-those-who-don-t-have-strong-institutions&quot;&gt;For those who don&#x27;t have strong institutions&lt;&#x2F;h1&gt;
&lt;p&gt;I know Bitcoin is having some success where the commerce of the state is failing, for various reasons. I don&#x27;t have a good answer for that use case. But I don&#x27;t believe in the long run, that Bitcoin successfully replaces the institutions of banking, legal recourse, and security for those who don&#x27;t have those institutions.&lt;&#x2F;p&gt;
&lt;p&gt;So there are very real problems to be solved here, and I understand why Bitcoin does get involved, but I think we should demand more here, not try to duct tape a severely flawed solution that forgets what purposes institutions serve in our lives. &lt;&#x2F;p&gt;
&lt;h1 id=&quot;summary&quot;&gt;Summary&lt;&#x2F;h1&gt;
&lt;p&gt;While I&#x27;m sure there are some who will sit around and say all of these are features. The times the court fail, government mistakes, illegitimate power of attorney occur could all be avoided with Bitcoin. No one should be able to force you to pay a penny you don&#x27;t want to.&lt;&#x2F;p&gt;
&lt;p&gt;But in my opinion, Bitcoin simply isn&#x27;t a technology the vast majority of the populace can use safely, or to achieve goals they can easily do with the current banking system.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>Comments are for why, not what</title>
		<published>2022-04-30T00:00:00+00:00</published>
		<updated>2022-04-30T00:00:00+00:00</updated>
		<link href="https://wdkwwdk.com/posts/comments/" type="text/html"/>
		<id>https://wdkwwdk.com/posts/comments/</id>
		<content type="html">&lt;p&gt;I suspect too many dev teams have gone a bit too far the mantra of code should be self documenting. When interviewing developers, this is something I often pick up as a negative signal, is poor commenting style.&lt;&#x2F;p&gt;
&lt;p&gt;So this is just a reminder, that the code tells you what and how, and should be as clearly written as possible for other developers to follow using just the code. But this mantra doesn&#x27;t mean there should be no comments... comments are still important to indicate to the reader why a piece of code exists.&lt;&#x2F;p&gt;
&lt;p&gt;If a piece of code exists to implement a customer requirement, link to that requirement, external source of information, or simply explain the problem being solved. Otherwise, those who come after you, including yourself, will be doomed to repeat a bug, lose a requirement, or be stuck when changing code later.&lt;&#x2F;p&gt;
&lt;p&gt;See &lt;a href=&quot;https:&#x2F;&#x2F;blog.codinghorror.com&#x2F;code-tells-you-how-comments-tell-you-why&#x2F;&quot;&gt;Code Tells You How, Comments Tell You Why - Coding Horror&lt;&#x2F;a&gt; for a better explanation.&lt;&#x2F;p&gt;
</content>
	</entry>
	<entry xml:lang="en">
		<title>We don&#x27;t know what we don&#x27;t know</title>
		<published>2020-07-16T00:00:00+00:00</published>
		<updated>2020-07-16T00:00:00+00:00</updated>
		<link href="https://wdkwwdk.com/posts/we-dont-know/" type="text/html"/>
		<id>https://wdkwwdk.com/posts/we-dont-know/</id>
		<content type="html">&lt;p&gt;Sometimes it&#x27;s important to remind ourselves that we don&#x27;t know what we don&#x27;t know!&lt;&#x2F;p&gt;
&lt;p&gt;I recently began to spend more effort considering and emphasizing what pieces might be missing from a particular engineering puzzle. Like many engineers, I rely heavily on mental models when tackling technical problems. The problem is, these mental models are seldom complete, with gaps or assumptions, which leads to mistakes or discounting approaches to a question we didn&#x27;t know to consider.&lt;&#x2F;p&gt;
&lt;p&gt;Let&#x27;s spend some time considering what it means not to know what we don&#x27;t know and how we can remind ourselves of some of our own biases.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;my-first-experience-with-wdkwwdk&quot;&gt;My first experience with WDKWWDK&lt;&#x2F;h2&gt;
&lt;p&gt;For me, this realization first came during a meeting.&lt;&#x2F;p&gt;
&lt;p&gt;We were trying to tackle a specific security challenge that required selecting a cryptographic protocol with particular properties. I was in the position to make the recommendations, which came down to &lt;a href=&quot;http:&#x2F;&#x2F;www.noiseprotocol.org&quot;&gt;Noise&lt;&#x2F;a&gt; based on some &lt;a href=&quot;https:&#x2F;&#x2F;latacora.com&quot;&gt;industry experts&#x27;&lt;&#x2F;a&gt; suggestions.&lt;&#x2F;p&gt;
&lt;p&gt;The problem we had is we weren&#x27;t able to locate an implementation of the protocol for our embedded CPU. While I was evolving into a security lead for the team with a better than average understanding of security principles, I was utterly ill-prepared to write a crypto implementation that would pass any scrutiny.&lt;&#x2F;p&gt;
&lt;p&gt;However, with the most knowledge, the team asked me to develop the implementation.&lt;&#x2F;p&gt;
&lt;p&gt;I objected, indicating that writing a cryptographic implementation is detailed work, and it&#x27;s challenging to be sure that the implementation is correct.&lt;&#x2F;p&gt;
&lt;p&gt;The team countered, saying that it must be correct if the implementation can communicate with another library (on a known CPU architecture).&lt;&#x2F;p&gt;
&lt;p&gt;The problem is it&#x27;s possible to write a compatible protocol implementation, that has significant security problems. Re-using nonces or timing attacks could ruin our day, and we&#x27;d easily miss out on the security properties we desired.&lt;&#x2F;p&gt;
&lt;p&gt;The team countered again, indicating that if I knew about problems like nonce re-use or timing attacks, that I should avoid those problems. &lt;&#x2F;p&gt;
&lt;p&gt;Any problem I can describe in theory should be a problem I can avoid.&lt;&#x2F;p&gt;
&lt;p&gt;Eventually, I had to figure out to approach this engineering conversation as an admission, I don&#x27;t know what I don&#x27;t know, so I&#x27;m ill-prepared to solve problems I don&#x27;t even know to avoid. &lt;&#x2F;p&gt;
&lt;p&gt;Not only did I need to admit what I didn&#x27;t know, but as a team, we had to admit combined that we didn&#x27;t know what we didn&#x27;t know. In many scenarios, we may be able to get away with this, but here, a failure meant we failed to deliver on our security promises to our customers.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;is-this-the-dunning-kruger-effect&quot;&gt;Is this the Dunning-Kruger effect?&lt;&#x2F;h2&gt;
&lt;p&gt;For those who aren&#x27;t familiar, a simplified version of the Dunning-Kruger effect states that a cognitive bias exists where individuals with limited knowledge or competence in a given intellectual domain greatly overestimate their expertise or skill in that domain. And that those with a great deal of expertise tend to underestimate their results. &lt;&#x2F;p&gt;
&lt;p&gt;This cognitive bias is fascinating and may explain some of the &amp;quot;solutions&amp;quot; or &amp;quot;projects&amp;quot; we see that claim perfect security while not holding up to basic scrutiny.&lt;&#x2F;p&gt;
&lt;p&gt;While the Dunning-Kruger effect may apply here, we often forget that this cognitive bias only means that people scoring in the 12th percentile had ranked themselves in the 62nd percentile. But those in the 90th percentile had self-assessed to be within the ~75th percentile. &lt;&#x2F;p&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;www.researchgate.net&#x2F;profile&#x2F;David_Dunning2&#x2F;publication&#x2F;12688660&#x2F;figure&#x2F;fig1&#x2F;AS:394431292297232@1471051156893&#x2F;Perceived-ability-to-recognize-humor-as-a-function-of-actual-test-performance-Study-1.png&quot; alt=&quot;Image from Dunning-Kruger Research&quot; &#x2F;&gt;
&lt;a href=&quot;https:&#x2F;&#x2F;www.researchgate.net&#x2F;figure&#x2F;Perceived-ability-to-recognize-humor-as-a-function-of-actual-test-performance-Study-1_fig1_12688660&quot;&gt;Dunning-Kruger effect on research gate for more information&lt;&#x2F;a&gt;
&lt;br &#x2F;&gt;&lt;br &#x2F;&gt;&lt;&#x2F;p&gt;
&lt;p&gt;With this in mind, on average, individuals without much exposure do not rank themselves as experts in an area they don&#x27;t know.&lt;&#x2F;p&gt;
&lt;p&gt;We can still draw an important lesson here; that we need to be aware of and careful of our biases, whether it be the Dunning-Kruger effect or something else.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;unconscious-fear&quot;&gt;Unconscious Fear&lt;&#x2F;h2&gt;
&lt;p&gt;&lt;img src=&quot;https:&#x2F;&#x2F;imgs.xkcd.com&#x2F;comics&#x2F;ten_thousand.png&quot; alt=&quot;xkcd 1053&quot; &#x2F;&gt;
&lt;a href=&quot;https:&#x2F;&#x2F;xkcd.com&#x2F;1053&#x2F;&quot;&gt;xkcd 1053&lt;&#x2F;a&gt;&lt;&#x2F;p&gt;
&lt;p&gt;As engineers, I think we get used to analyzing complex problems and coming back with answers. Especially those of us who are known for digging in and finding the solutions.&lt;&#x2F;p&gt;
&lt;p&gt;When given a task, there may also be a particular fear associated with not having the answer. If your leadership or team members expect you are an expert in a domain and are assigned a problem, it feels like a failure to return without the full solution. &lt;&#x2F;p&gt;
&lt;p&gt;For me, it&#x27;s even come to the point where others have tried shame me in front of my peers for not knowing some technical detail off hand. This behaviour creates perverse incentives that it&#x27;s better to stick with an assumption than admit we don&#x27;t know something. I know I&#x27;ve unconciously affected others in this same way, which is one of my regrets. &lt;&#x2F;p&gt;
&lt;p&gt;A large part of this is realizing it&#x27;s not a failure to admit that we have missing knowledge. We may not remember some details or have more research to do. Maybe there is no action required. The failure is to proceed without identifying the risk of the missing information. Whether an expert or not, there are always going to be missing details. When working in security, the missed detail could be the difference between high and abysmal security. In other domains, the risks may be much different.&lt;&#x2F;p&gt;
&lt;p&gt;Knowing the risks of missing information allows us to choose whether to accept those risks. &lt;&#x2F;p&gt;
&lt;h2 id=&quot;how-do-i-apply-this&quot;&gt;How do I apply this?&lt;&#x2F;h2&gt;
&lt;p&gt;I think it&#x27;s as simple as stating, &amp;quot;We don&#x27;t know what we don&#x27;t know&amp;quot; in a conversation, or typing WDKWWDK into a document or chat session. And ensuring our teams and leaders don&#x27;t allow a stigma to exist around not knowing some details.&lt;&#x2F;p&gt;
&lt;p&gt;I&#x27;m not the &lt;a href=&quot;https:&#x2F;&#x2F;shaker.com&#x2F;questions-your-company-needs-to-be-asking-itself-and-acting-on-now&#x2F;&quot;&gt;first&lt;&#x2F;a&gt; to use this acronym, but I also don&#x27;t believe we use it enough.&lt;&#x2F;p&gt;
&lt;p&gt;This statement of fact, acts as a reminder, that we should step back and consider how our biases may impact a particular decision or design and to identify what information may be missing.&lt;&#x2F;p&gt;
&lt;p&gt;We can then consider:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;What we know&lt;&#x2F;li&gt;
&lt;li&gt;What we know we don&#x27;t know&lt;&#x2F;li&gt;
&lt;li&gt;If there is anything we don&#x27;t know what we don&#x27;t know that needs exploration&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;And decide on the risks of proceeding with missing information, cognizant that there will always be missing information.&lt;&#x2F;p&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;&#x2F;h2&gt;
&lt;p&gt;Before committing to an approach to an engineering problem, remind yourself or the team that there are likely missing details that may affect the outcome. How to proceed largely depends on the risks involved, topics like security have different risks than the CI&#x2F;CD pipeline. &lt;&#x2F;p&gt;
&lt;p&gt;And we need to remind ourselves and our peers to avoid the stigmas and biases introduced by admitting we don&#x27;t know things. Being an expert in a domain like security, doesn&#x27;t mean memorization of every algorithm, every protocol, or approach.&lt;&#x2F;p&gt;
</content>
	</entry>
</feed>
